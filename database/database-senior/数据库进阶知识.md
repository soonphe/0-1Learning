# 0-1Learning

![alt text](../../static/common/svg/luoxiaosheng.svg "公众号")
![alt text](../../static/common/svg/luoxiaosheng_learning.svg "学习")
![alt text](../../static/common/svg/luoxiaosheng_wechat.svg "微信")


## 数据库进阶知识

### 规则
传统数据库遵循ACID规则：Atomic（原子性)Consistency（一致性）Isolation（隔离性）Durability（持久性）
NoSql一般为分布式，遵循CAP定理：一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）


### 修改字段及属性
数据库中修改字段名：
  mysql中：alter table adminuser change AU_name（列名） namee（新列名） varchar(255)（原始列名属性）
	 注：数据类型的修改可以  使列名不变，只修改后面的列名属性
  oracle中：使用rename关键字来实现字段名的修改:alter table 表名 rename column 旧的字段名 to 新的字段名名;
	    使用modify关键字来实现对数据类型的修改:alter table 表名 modify 字段名 数据类型;
  sqlserver：改变字段名：ALTER TABLE table_name RENAME COLUMN old_name to new_name;
	  改变数据类型：ALTER TABLE table_name ALTER COLUMN column_name datatype
	  增加或删除列：ALTER TABLE table_name ADD（删除使用drop） column_name datatype（删除没有datatype）

### key和index的区别
* key 是数据库的物理结构，它包含两层意义和作用，
一是约束（偏重于约束和规范数据库的结构完整性），
二是索引（辅助查询用的）。
包括primary key, unique key, foreign key 等。
primary key 有两个作用，一是约束作用（constraint），用来规范一个存储主键和唯一性，但同时也在此key上建立了一个index；
unique key 也有两个作用，一是约束作用（constraint），规范数据的唯一性，但同时也在这个key上建立了一个index；
foreign key也有两个作用，一是约束作用（constraint），规范数据的引用完整性，但同时也在这个key上建立了一个index；

* INDEX
index是数据库的物理结构，它只是辅助查询的，它创建时会在另外的表空间（mysql中的innodb表空间）以一个类似目录的结构存储。索引要分类的话，分为前缀索引、全文本索引等；因此，索引只是索引，它不会去约束索引的字段的行为。
例如：create table t(id int, index inx_tx_id (id));


### 复合主键
所谓的复合主键 就是指你表的主键含有一个以上的字段组成,不使用无业务含义的自增id作为主键。
~~~~
create table test 
( 
   name varchar(19), 
   id number, 
   value varchar(10), 
   primary key (name,id) 
) 
~~~~
举个例子，我们在表中创建了一个ID字段，自动增长，并设为主键，这个是没有问题的，因为“主键是唯一的索引”，ID自动增长保证了唯一性，所以可以

此时，我们再创建一个字段name，类型为varchar，也设置为主键，你会发现，在表的多行中你是可以填写相同的name值的，这岂不是有违“主键是唯一的索引”这句话么？

所以我才说“主键是唯一的索引”是有歧义的。应该是“当表中只有一个主键时，它是唯一的索引；当表中有多个主键时，称为复合主键，复合主键联合保证唯一索引”。

为什么自增长ID已经可以作为唯一标识的主键，为啥还需要复合主键呢。因为，并不是所有的表都要有ID这个字段，比如，我们建一个学生表，没有唯一能标识学生的ID，怎么办呢，学生的名字、年龄、班级都可能重复，无法使用单个字段来唯一标识，这时，我们可以将多个字段设置为主键，形成复合主键，这多个字段联合标识唯一性，其中，某几个主键字段值出现重复是没有问题的，只要不是有多条记录的所有主键值完全一样，就不算重复。


### 锁级别
* 行级锁：容易造成死锁
* 表级锁：锁住整张表

### 悲观锁和悲观锁
* 悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。再比如Java里面的同步原语synchronized关键字的实现就是悲观锁，volatile关键字虽然是synchronized关键字的轻量级实现，但是其无法保证原子性，所以一般也要搭配锁使用。
* 乐观锁：顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。

### 数据库的隔离级别：
* 读未提交（Read Uncommitted）：只处理更新丢失。如果一个事务已经开始写数据，则不允许其他事务同时进行写操作，但允许其他事务读此行数据。可通过“排他写锁”实现。
* 读提交（数据库引擎的默认级别）（Read Committed）：处理更新丢失、脏读。读取数据的事务允许其他事务继续访问改行数据，但是未提交的写事务将会禁止其他事务访问改行。可通过“瞬间共享读锁”和“排他写锁”实现。
* 可重复读取（Repeatable Read）：处理更新丢失、脏读和不可重复读取。读取数据的事务将会禁止写事务，但允许读事务，写事务则禁止任何其他事务。可通过“共享读锁”和“排他写锁”实现。
* 序列化（Serializable）：提供严格的事务隔离。要求失去序列化执行，事务只能一个接一个地执行，不能并发执行。仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。

### 事务容易出现的问题及解决
脏读：（同时操作都没提交的读取）READ_COMMITTED解决
不可重复读：（同时操作，事务一分别读取事务二操作时和提交后的数据，读取的记录内容不一致）REPEATABLE_READ解决
幻读：（和可重复读类似，但是事务二的数据操作仅仅是插入和删除，不是修改数据，读取的记录数量前后不一致）SERIALIZABLE_READ解决


### innodb的半一致性读？
什么是半一致性读

就是发生在update语句中。在RC隔离级别或者innodb_locks_unsafe_for_binlog被设置为true，并发时，如果update的记录发生锁等待，那么返回该记录的prev 版本（在返回前会将锁等待的这个lock从trx中删除掉），到mysql层进行where判断，是否满足条件。如果满足where条件，那么再次进入innodb层，真正加锁或者发生锁等待。

这样做的好处是：减少同一行记录的锁冲突及锁等待；无并发冲突时，直接读取最新版本加锁，有冲突时，不加锁，读取prev版本不需要锁等待。

缺点：非冲突串行话策略，对于binlog来说是不安全的。只能发生在RC隔离级别和innodb_lock_unsafe_for_binlog下。


### 状态分类，分别降序、升序排列
例：按状态分类，分别降序、升序排列
~~~~
①
select * from test order by
case when state='已完成' then id end,
case when state='未完成' then state end,id desc
②
select * from test order by
case when state='已完成' then id end asc,
case when state='未完成' then id end desc,state desc
~~~~


### 获取当前日期和及时分秒信息
~~~~
SELECT curdate();
| 2013-07-29 |
~~~~

~~~~
mysql> select now();
| 2013-07-29 22:10:40 |
获取近三天：昨天，今天，明天
select * from t_clue_follow_record 
where creator_id = 999 
AND invite_time >= DATE_SUB(curdate(),INTERVAL +1 DAY) 
and  invite_time <= DATE_SUB(curdate(),INTERVAL -1 DAY)
~~~~

### sql insert 内容中，部分为查询的结果
普通插入时，我们只能：
```
insert into Zd(userId,url,others)values('id','aaaaa',‘others...’)
```
插入“动态”数据，即某些数据是查询结果，而某些数据是写死的，就可以写成这样：
```
insert into Zd(userId , url, others)
select top 1 id , 'aaaaa', 'others...'
from userInfo
```
即把写死的数据按顺序用逗号分隔加到 from 前。下面这条也是同样的效果：
```
insert into Zd(url, userId , others)
select top 1 'aaaaa', id , 'others...'
from userInfo
```

### MySQL中的field（）函数 
MySQL中的field（）函数，可以用来对SQL中查询结果集进行指定顺序排序。不在field中的字段放在最前面，其他则按filed中的顺序排序
根据输入的字段排序
```
...
order by field (trade_flow_no,'1','2','3')
```
```
假设test表中有a,b字段

a字段中有1,2,3,4,5,6,7,8,9,10...

要求：8,9,7先排序，剩下的按照b字段正序排列

select * from test order by field(a,7,9,8) desc , b asc

注意：这里field中的值顺序是相反的，field方法后面需要加上desc 否则会先按照 b字段 正序，再按照field中的顺序进行排列
```

### mysql 缓存问题，一致性问题
mysql的自带缓存是为了解决io效率的问题，本身就没保证强一致，就是为了让一些读热点页不用每次都去磁盘io，或者做非主键索引写的异步刷盘
一致性可是靠wal，redolog，binlog保证的
读不用说，写有wal，写成功了才算提交成功，崩溃恢复啥的也是从log里恢复啊。有脏页的话，只要触发了读和写一定先要purge的，还有双写

### mysql WAL机制
MySQL 里经常说到的 WAL技术，也就是先写日志，再写磁盘。
当内存数据页跟磁盘数据页内容不一致的时候，我们成这个内存页为“脏页”。内存数据写入磁盘后，内存和磁盘上的数据页内容就一致了，称为“干净页”。
MySQL 从 内存更新到磁盘的过程，称为刷脏页的过程（flush）。

- InnoDB 刷脏页的时机：
1. 内存中的redo log 写满了，这时系统就会停止所有更新操作，把checkoutpoint 往前推，redo log留出空间可以继续写。
往前推进之后，就要把两个点之间的日志对应的所有脏页都 flush 到磁盘上。
这种情况是 InnoDB 要尽量避免的。因为出现这种情况，整个系统都不能接受更新。更新数会跌为0。

2. 系统中内存不足时，当这个时候需要新的数据页到内存中，就要淘汰掉一些数据页，如果淘汰的是“脏页”，就要先将“脏页”写到磁盘。
那么为什么不能直接淘汰所有的内存，下次请求的时候，再从磁盘读入数据页，然后 拿 redo log 出来应用？这其实也是从性能的角度来考虑的，刷脏页一定写盘，就保证了每个数据页只有两种情况：

数据页直接在内存里，内存里的肯定是正确的，直接返回
内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。 这样的效率最高。
这种情况在日常应用中其实是常态。在InnoDB 中，使用缓冲池 （buffer pool）管理内存，缓冲池中的内存页有三种状态：

- 还没有使用的；
- 使用了并且是干净页
- 使用了并且是脏页
3. 数据库空闲的时候刷脏页。
4. 数据库正常关闭的时候，也要把内存中所有的脏页全都flush 到磁盘上。

对性能的影响
刷脏页是常态，所以如果出现以下的情况，都会明明显影响性能：
- 一个查询要淘汰的脏页太多，会导致查询的响应时间明显变长；
- 日志写满，更新全部堵住，写性能跌为0，这种情况对于敏感业务来说是不能接受的。

binlog 的写入机制
binlog 的写入机制比较简单：事务执行的过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到binlog 文件中。
系统给 binlog cache 分配了一片内存，每个线程一个，参数 binglog_cache_size 用于控制单个线程内 binlog cache 的内存大小，超过就要暂存在磁盘。
事务提交的时候，执行器把 binlog cache 里完整事务写入到 binlog 中，并清空 binlog cache。

- write 指的是把日志写入到文件系统的 page cache，并没有吧数据持久化到磁盘，所以速度比较快。
- fsync 是持久化到磁盘的操作，一般情况下， fsync 才会占磁盘的 IOPS。
write 和 fsync 的时机，是由参数 sync_binlog 控制的：

- sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；
- sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；
- sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。
因此，在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。

- redo log 的写入机制
事务的执行过程中，生成的 redo log 是要先写到 redo log buffer 的。

redo log 三种状态：

- 存在 redo log buffer 中，物理上是在 MySQL 进程内存中
- 写到磁盘（write），但是没有持久化（fsync），物理上是在文件系统的 page cache 里
- 持久化磁盘，对应的是 hard disk
日志写到 redo log buffer 是很快的，write 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了。

### mysql 双写机制
一：为啥会有两次写？必要了解partial page write 问题 :
InnoDB 的Page Size一般是16KB，其数据校验也是针对这16KB来计算的，将数据写入到磁盘是以Page为单位进行操作的。
而计算机硬件和操作系统，写文件是以4KB作为单位的,那么每写一个innodb的page到磁盘上，在os级别上需要写4个块.

在极端情况下（比如断电）往往并不能保证这一操作的原子性，16K的数据，写入4K 时，发生了系统断电/os crash ，只有一部分写是成功的，这种情况下就是 partial page write 问题。
有人会想到系统恢复后MySQL可以根据redolog 进行恢复，而mysql在恢复的过程中是检查page的checksum，checksum就是page的最后事务号，发生partial page write 问题时，page已经损坏，找不到该page中的事务号，就无法恢复。

为了解决 partial page write 问题 ，
- 当mysql将脏数据flush到data file的时候, 先使用memcopy 将脏数据复制到内存中的double write buffer ，
- 通过double write buffer再分2次，每次写入1MB到共享表空间，
- 然后马上调用fsync函数，同步到磁盘上，避免缓冲带来的问题。

在这个过程中，doublewrite是顺序写，开销并不大，在完成doublewrite写入后，在将double write buffer写入各表空间文件，这时是离散写入。如果发生了极端情况（断电），InnoDB再次启动后，发现了一个Page数据已经损坏，那么此时就可以从doublewrite buffer中进行数据恢复了。
两次写需要额外添加两个部分：

- 内存中的两次写缓冲（doublewrite buffer），大小为2MB
- 磁盘上共享表空间中连续的128页，大小也为2MB。其中120个用于批量写脏页，另外8个用于Single Page Flush。做区分的原因是批量刷脏是后台线程做的，不影响前台线程。而Single page flush是用户线程发起的，需要尽快的刷脏页并替换出一个空闲页出来。







