# 0-1Learning

![alt text](../static/common/svg/luoxiaosheng.svg "公众号")
![alt text](../static/common/svg/luoxiaosheng_learning.svg "学习")
![alt text](../static/common/svg/luoxiaosheng_wechat.svg "微信")


## mysql开发规范

### 一、基础规范
- 数据库表存储引擎默认为InnnoDB，禁止使用MyISAM，特殊情况需要使用非InnoDB存储引擎须和DBA沟通（InnnoDB支持事务、行级锁、并发性能更好）
- 使用utf8mb4字符集，可以根据需求自定义为utf8(默认统一使用utf8mb4字符集，防止因为关联导致索引失效或特殊字符乱码)
- 数据表、数据字段必须加入中文注释
- 禁止使用存储过程、视图、触发器、Event、自定义函数（高并发大数据的互联网业务，架构设计思路是“解放数据库CPU，将计算转移到服务层”，并发量大的情况下，这些功能很可能将数据库拖死，业务逻辑放到服务层具备更好的扩展性，能够轻易实现“增机器就加性能”。数据库擅长存储与索引，cpu建议上移。）
- 禁止使用外键约束，通过程序来控制主外键约束关系（update与delete操作都会涉及相关联的表，十分影响sql 的性能，甚至会造成死锁。高并发情况下容易造成数据库性能瓶颈，大数据高并发业务场景数据库使用以性能优先。）
- 禁止在数据库中存放图片、视频和文件等大的二进制数据（让数据库做它不擅长的事情，大文件和照片存储在文件系统，数据库里存URI多好）
- 字段尽量避免为not null，确实需要空值的情况，可以根据实际业务，可以增加默认值规避缺值报错（null值很难查询优化且占用额外的索引空间，推荐默认数值0或空字符串或时间戳替代null）
- 每张表必须有主键，自增或有序且无意义，避免多列主键，尽量不选择字符串列作为主键
- 只允许使用域名，而不是ip连接数据库
- 要经常使用explain，如果发现索引选择性差，优化索引


### 二、命名规范
- 所有数据库对象命名只能包含后面的三种字符【小写字母、阿拉伯数字、下划线】，必须见名知意，禁止拼音英文混用（例：数据库名称以业务线命名，表名也可以使用t_+"名称"形成表名，字段名使用c_+"字段名"，避免关键字冲突。）
- 数据库名尽量保持全公司唯一
- 所有数据库对象命名须见名知意
- 库名、表名、字段名最好别超过32个字符
- 索引命名：索引前缀 + 字段名，复合索引字段比较多时，可以简化字段名（例：唯一索引：uk_column_name  普通索引：idx_column_name）
- 临时库表必须以tmp_为前缀并以日期为后缀，备份表必须以bak_为前缀并以日期(时间戳)为后缀（例如：tmp_user_info_20200806    bak_user_info_20200806）
- 所有数据库对象名称禁止使用mysql保留关键字，如果包含保留关键字时，需要将其用反引号括起来（关键字详见：https://dev.mysql.com/doc/refman/5.7/en/keywords.html）
- 其他研发自定义的命名规则，如表名和字段名加上相关业务的前缀等等

### 三、设计规范

- 禁止存储明文密码、手机号、身份证号码等信息，建议敏感信息加密
- 单表不要有太多字段，建议在20以内，更多字段，考虑冷热字段分成不同表（字段太多，影响读写的性能）
- 单表数据量建议保持在500万以内，超过的数据可以做冷热数据分离或历史归档处理
- 多表中的相同列，必须保证列定义一致（字符集、字段类型）
- 避免隐式转换，查询的数据类型，一定要和字段的类型匹配，相同业务数据的字段设置相同的数据类型，防止在关联查询时数据类型不匹配，发生隐式转换
- 表尽量考虑增加记录create_time创建时间和update_time修改时间的字段（考虑后期可能的数据同步，用于保证数据一致性）
- 避免使用text、blob等数据类型，在满足需求的前提下，varchar长度越小越好
- 使用tinyint代替enum、bit等类型，而后是smallint（2位），值域比较大的情况用int（4）（bit 不能建索引，TINYINT可以建索引）
  - TINYINT是8位整数值，BIT字段只能存储1位BIT（1）和64位BIT（64）之间。对于布尔值，BIT（1）很常见。 如果确定只有2个状态，可以用bit，否则就用tinyint，以防今后就多个状态的可能。
- 使用decimal代替double、float等容易丢失精度的数据类型
- 避免使用字符串存储日期，尽量使用timestamp和datetime等日期类型（datetime直观，timestamp存储时间范围小，性能更好）（timestamp存储需要四个字节，它的取值范围为“1970-01-01 00:00:01” UTC ~ “2038-01-19 03:14:07” （和时区有关））
- 尽量使用int而非BIGINT，当然能使用TINYINT、SMALLINT、MEDIUM_INT更好（性能考虑、取值范围的问题，如果需要大于int的范围，就用bigint）
```
bigint带符号的范围是—9223372036854775808到9223372036854775807。无符号的范围是0到18446744073709551615。

int 普通大小的整数。带符号的范围是—2147483648到2147483647。无符号的范围是0到4294967295。

有符号int最大可以支持到约22亿，远远大于我们的需求和MySQL单表所能支持的性能上限。
对于OLTP应用来说，单表的规模一般要保持在千万级别，不会达到22亿上限。如果要加大预留量，可以把主键改为改为无符号int，上限为42亿，这个预留量已经是非常的充足了。
使用bigint，会占用更大的磁盘和内存空间，内存空间毕竟有限，无效的占用会导致更多的数据换入换出，额外增加了IO的压力，对性能是不利的。
```
- 整型来存IP，经纬度采用GeoHash（性能和查询考虑）
```
对于转换来说，MySQL提供了相应的函数来把字符串格式的IP转换成整数INET_ATON，以及把整数格式的IP转换成字符串的INET_NTOA。如下所示：
mysql> select inet_aton('192.168.0.1');  
mysql> select inet_ntoa(3232235521);  
对于转换字符串IPv4和数值类型，也可以放在应用层

相对字符串存储，使用无符号整数来存储有如下的好处：
- 节省空间，不管是数据存储空间，还是索引存储空间
- 便于使用范围查询（BETWEEN...AND），且效率更高

使用无符号整数来存储也有缺点：不便于阅读、需要手动转换

通常，在保存IPv4地址时，一个IPv4最小需要7个字符，最大需要15个字符，所以，使用VARCHAR(15)即可。MySQL在保存变长的字符串时，还需要额外的一个字节来保存此字符串的长度。而如果使用无符号整数来存储，只需要4个字节即可。
另外还可以使用4个字段分别存储IPv4中的各部分，但是通常这不管是存储空间和查询效率应该都不是很高（可能有的场景适合使用这种方式存储）。
```

#### 索引
- 尽量让查询都应该走索引，除非表的行数很少（<=100，并且将来也大概率不超过）
- 尽量避免索引重复，避免在低基数列上建立索引，例如“性别”（通过索引过滤出的数据量如果过大（如过万），可能会造成慢查询 ）
- 尽量避免在WHERE子句中对字段进行NULL值判断（引擎会放弃使用索引而进行全表扫描，造成慢查询）
- 尽量避免在WHERE子句索引列进行数学运算和函数运算，如使用!=、<>、前缀%的like（mysql在使用like查询中，但只有使用后面的%时，才会使用到索引）等造成索引失效（否则引擎放弃使用索引而进行全表扫描（除非where中还有其它可索引条件））
```
例：select id where age+1=10  无法使用索引
任何对列的操作都将导致表扫描，它包括数据库函数。

例：where date(create_time)='2020-08-10'  无法使用索引
可以改写为 where create_time >= '2020-08-10' and create_time < '2020-08-11'
```
- 单表的索引数量不建议超过5-15个，覆盖索引的字段，建议不超过5个
```
索引并不是越多越好（一般不超过5个），要根据查询有针对性的创建，考虑在where和order by命令上涉及的列建立索引，可根据explain来查看是否使用了索引还是全表扫描（过多占用磁盘空间及数据库的内存空间）
```
- 对字符串使⽤用前缀索引，前缀索引长度不超过8个字符
- 区分度最大的索引字段放在前面，核⼼SQL优先考虑覆盖索引

#### 增删改查
- 避免使用select *
- 拒绝大事务，建议分拆成多个小事务
- 注意控制where in 条件的数量（建议<=100，mysql5.7版本更新为200，超过200则走索引统计，性能下降）
- where条件有多个索引的，实际只会走其中一个，如果无法明确多个索引会走哪一个，可以使用强制索引（需要数据库支持）
- 尽量避免多表join操作
- 避免子查询，使用连接（join）来代替子查询，如果可以用多次查询代替join，最好不用join（容易慢查询；将来如果拆库，可能落到两个表了）
- SQL中使用到OR的改写为用IN()。OR的效率没有IN的效率高，in里面数字的个数建议控制在 100 以内
- 使用EXIST代替IN，EXIST在一些场景查询会比IN快
- 尽量使用limit对查询结果的记录进行限定（建议<=500），除非使用ID或唯一键查询。如果确实需要查询大量，可循环查询（循环最好有次数限制+超出告警）（一次太多数据容易慢查询+网络传输耗时高）
- 避免深度分页（如，limit 10000,10）（深度分页效率低原因： limit m,n 查询过程是先回表查询m+n条记录，然后丢掉前m条，取后面n条结果返回）
```
可以使用 where (update_time={lastTime} and id>{lastId}) or update_time>{lastTime} order by update_time,id limit 10 形式代替（或只按id条件）
lastId为上一次查询最后一条记录的ID（入参），update_time为上一次查询最后一条记录的update_time
上述用于数据增量同步时，可查出指定时间内，数据发生了变化的数据
```
- APP（及小程序等）分页（上拉下拉操作），与WEB分页不同，不建议采用limit m,n（limit m,n 方式，两次查询之间如果有新数据生成或删除，则查询的数据会前一页的重复或缺失（APP一般是连续显示数据，WEB页通常不是））

- 插入数据，如果需要保证不重复，最好有唯一索引（没有唯一索引时，通过exists判断，在并发下有概率生成多条）
- 更新&删除，最好先查出数据（日志&check数量），再通过ID作为where条件处理（包括批量处理）（可有效避免死锁&慢查询。非ID更新或删除容易超出预期（先查数据，再处理，不易出错，错了也容易发现））
- 批量更新&删除，一次不宜过多（建议<=200），大量数据清洗&删除，建议循环处理并可中断&断点继续处理、写可灰度可降级（降级为只读）（一次过多，容易对主从延迟及数据同步造成影响）
- DRDS，按ID更新或删除数据时，需要增加分库键：update set ... where id=? and {key}=?（没有分库键，会导致全物理MySQL实例都会执行一次同一SQL）


### 四、权限和行为规范
- 最小权限原则
  - 默认程序用户给予select、insert、update、delete四种权限，如有特殊需求，请与DBA沟通
  - 默认程序用户给予应用网段权限，如需要从应用网段之外访问，请与DBA沟通
  - 每个应用程序建立独立数据库账号
  - 禁止跨库查询
- 研发查询业务数据可通过sql审核平台来进行查询，须提前在平台申请权限（结果集条数受限于申请权限时的限制行数）
- 数据导出可以通过sql审核平台来操作，导出条数受限于申请权限时的限制行数
- 研发对线上数据查询和操作均需通过sql审核平台
- 大表的DDL操作、批量操作或者大数据量的操作，须提前与DBA沟通
- 单表的多个alter操作，建议合并成一个操作

### 五、应用

#### 2、唯一ID生成

      i、数据库主键自增（建议方案）：多数场景（QPS写入不太大），不分库分表。

      ii、使用表存储自增值（建议方案）：分库分表时的同一逻辑表，对ID顺序性要求不高

        表seq_table，字段name（主键+唯一），字段sequence_value（顺序值），字段step（步长），字段version（版本）

        假设对user分库或分表，现向其插入一条数据，操作如下

1	如果内存中有name='user'的数据，并且sequence_value<maxValue，sequence_value值+1并返回（此整个过程synchronized）
2	否则：select sequence_value,step,version from seq_table where name='user'
3	update seq_table set sequence_value=sequence_value+step,version=version+1 where name='user' and version=${version}   //version为上一条查询的结果
4	将内存中name='user'的数据，更新maxValue为sequence_value+step
5	sequence_value值+1并返回
对于有时序要求的，也可参考上述算法，加上时间戳字段。

      上述算法，即使对于上万写入QPS，也可以很好支撑（对sequence_value表取一当百或更多）。

      当前应用的机器宕机或重启中会有部分ID弃用。

      iii、雪花算法：适用于写入QPS很大（如过万），要求ID有一定顺序性。需要考虑时间回退问题。

      iV、UUID：适用于ID要求随机性。性能较差。

#### 3、防拖库

     场景：唯一ID具体一定顺序性，能通过编程方式将相关数据快速下载（通过增长数据主键），泄露业务数据或隐私数据

     接口设计时参数增加一个校验码，校验码由表中固定不易变的非公开字段（身份证/手机号或其它）散列或加密生成；接口中对参与与DB中的结果进行比对，失败则返回一个可用的非正确结果（避免对方程序直接发现，增加其成本）。

#### 4、乐观锁

     适用场景：防止数据并发问题。与使用redis等分布式锁相比，架构简单，更加轻量级。

     数据插入：使用表唯一键（可以是多个字段组合唯一）

     数据更新：

       i、利用时间戳：update a set update_time=sysdate() ,  ...   where id=${id} and update_time=${updateTime}  //updateTime为前一次查询得到的表更新时间，适用几乎不可能存在同时更新同一ID的场景

       ii、利用版本字段：update a set version=version+1,  ...   where id=${id} and version=${version}  //version为前一次查询得到的版本值

      iii、利用状态字段：update a set status=2,  ...   where id=${id} and status=1  //适用于status字段值不可回退的场景（如订单状态）

    数据插入&更新混合使用：

      利用上述方式，保证第一条SQL采用了乐观锁或插入的唯一性，更新操作之后需要检查是否有成功更新的数据，保证整个操作的事务性。

#### 5、分库分表

    场景：DRDS / 单表数据量过大 / 单库写入能力不足

    路由算法：

     i、增长模式：id <= n 写入第一个表/库，<= 2n 写入第二个，以此类推。随业务变化、用户失活等，会有DB访问不均衡问题。

     ii、hash算法：id % n （n为表/库的数量），依次写入对应的表/库。扩容难（复制数据问题）

     iii、一致性hash算法：请自行百度，redis/kafka等均采用类似算法，扩容比hash算法容易（复制更少的数据）

     iv、自定义静态路由：维护一份相对静态的路由表（需要保障路由数据一致性），适用于分库/表维度数据不太大

        如结合hash算法：在某时间点前是6个DB实例，之后是8个；之前的分库维度按6个分库并存储&缓存，之后按8个分库逻辑计算。扩容时数据也不需要迁移，也基本没有DB访问不均衡问题。

问题：

       CURD均必须带上分表分库的条件。

        数据关联查询、跨库事务等需要在分库分表前应尽力避免（前者可采用ES解决）。


